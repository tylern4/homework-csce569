\documentclass[a4paper]{article}

\usepackage{fullpage} % Package to use full page
\usepackage{parskip} % Package to tweak paragraph skipping
\usepackage{tikz} % Package for drawing
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{verbatimbox}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{subfigure}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}
\lstset{ %
  backgroundcolor=\color{white},   % choose the background color
  basicstyle=\footnotesize,        % size of fonts used for the code
  numberstyle=\tiny,
  breaklines=true,                 % automatic line breaking only at whitespace
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  keywordstyle=\color{blue},       % keyword style
  stringstyle=\color{mymauve},     % string literal style
}

\title{CSCE 569: Homework 1}
\author{Nick Tyler}
\date{02/09/18}

\begin{document}

\maketitle

\section*{Matrix Matrix Multiplication}
Mathematically matrix multiplication between two matrices, A and B size M$\times$L and L$\times$N respectfully, to form the resultant matrix C with size M$\times$N. With the elements of the resulting matrix C defined by: $c_{ij} = \sum_{k} a_{ik}b_{kj}$ 
The mathematical, row major representation can be translated into an algorithm as seen below, where the new element of C is calculated by taking the values of the i'th row of matrix A and j'th column of matrix B multiplying them together and then adding them to a temporary value. The row of A and column of B are then walked through, multiplied together and then summed until all columns of A and rows of B are accounted for.

\begin{lstlisting}[language=C++]
for (i = 0; i < N; i++){ // Loop over cols
  for (j = 0; j < M; j++) { // Loop over rows
    float temp = 0.0; // Create temp to for new element
    for (w = 0; w < K; w++) // Walk through the row/column
      temp += A[i * K + w] * B[w * M + j]; // Add the product of elements
    C[i * M + j] = temp; // Put element into output matrix
  }
}
\end{lstlisting}


Depending on how the matrix is stored in memory the algorithm must be modified slightly. The skeleton of the algorithm stays the same, the only change is to how the elements of A and B are accessed in memory. This modification to the fifth line of the algorithm can be seen below.

\begin{lstlisting}[language=C++]
temp += A[i * K + w] * B[w * M + j]; // A Row, B Row
temp += A[w * K + i] * B[w * M + j]; // A Col, B Row
temp += A[w * K + i] * B[j * M + w]; // A Row, B Col
temp += A[i * K + w] * B[j * M + w]; // A Col, B Col
\end{lstlisting}

\section*{Matrix Vector Multiplication}
Matrix vector multiplication is just a special case of matrix multiplication where a matrix A of size M$\times$N is multiplied with a matrix B of size N$\times$1, resulting in a matrix C of size M$\times$1. Again the elements of C are defined similarly with a summation over the products of the two matrices as shown: $c_{i} = \sum_{k} a_{ik}b_{k}$
And with an algorithm, as:

\begin{lstlisting}[language=C++]
for (i = 0; i < M; i++) { // Loop over rows
  float temp = 0.0; // Create temp to for new element
  for (j = 0; j < N; j++) { // Loop over cols
    temp += A[i * N + j] * B[j];  // Add the product of elements
  }
  C[i] = temp; // Put element into output vector
}
\end{lstlisting}

And once again the elements of A can be stored in row major or column major with the differences between how the elements of the matrix are stored and accessed in memory, changing how to access the elements of A is all that is needed.

\begin{lstlisting}[language=C++]
temp += A[i * N + j] * B[j];  // A Row major
temp += A[j * N + i] * B[j];  // A Col Major
\end{lstlisting}

\section*{Performance}
All performance results are from my personal computer running Ubuntu 17.10, Artful, with 16GB of ram and an intel core i7-3770, running at 3.4GHz.

The programs for Matrix Matrix and Matrix Vector multiplication were tested both with and without gcc optimization's. With gcc optimization's enabled (-O3) the compiler will attempt to optimize the executable for speed. There are many flags which are enabled with optimization but most likely one of the optimization's involving loop unraveling or vectorization are what helps to speed up the results. All the information on what the optimization and all the flags enabled was found at the \href{https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html}{online gcc optimization manual}.

The performance for matrix multiplication can be seen in the following graph. The worst performance came from A column major and B row major at 2048 with no optimization, and even with optimization's enabled it was not fast in it's execution time. However storing the matrices as column major gives the best performance, it is the fastest method both with and without optimization's enabled.

With matrix vector multiplication the row major matrix is faster than both implementations of the optimized column major matrix. This probably comes from the fact that by doing row major element searches in both the matrix and vector are continuous instead of having to access elements out of order.

\section*{Histogram}

A histogram of an image takes the color values of each pixel tallies up how many of each value are in the image. The basic algorithm is that if a color value is present, to add one to the current count. 
\begin{lstlisting}[language=C++]
  for (int i = 0; i < src.cols; i++) { // Loop over cols
    for (int j = 0; j < src.rows; j++) { // Loop over rows
      k = src.at<uchar>(j, i); // Get current value
      histogram[k] += 1; // Add one to the histogram 
    }
  }
\end{lstlisting} 




\pagebreak
\begin{figure}
\hfill
\subfigure[Matrix Matrix Performance]{\includegraphics[scale=0.2]{mm.png}}
\hfill
\subfigure[Matrix Vector Performance]{\includegraphics[scale=0.2]{mv.png}}
\hfill
\caption{Performance Graphs}
\end{figure}

\begin{verbnobox}[\footnotesize]
Architecture:        x86_64
CPU op-mode(s):      32-bit, 64-bit
Byte Order:          Little Endian
CPU(s):              8
On-line CPU(s) list: 0-7
Thread(s) per core:  2
Core(s) per socket:  4
Socket(s):           1
NUMA node(s):        1
Vendor ID:           GenuineIntel
CPU family:          6
Model:               58
Model name:          Intel(R) Core(TM) i7-3770 CPU @ 3.40GHz
Stepping:            9
CPU MHz:             3400.264
CPU max MHz:         3900.0000
CPU min MHz:         1600.0000
BogoMIPS:            6800.52
Virtualization:      VT-x
L1d cache:           32K
L1i cache:           32K
L2 cache:            256K
L3 cache:            8192K
NUMA node0 CPU(s):   0-7
\end{verbnobox}

\end{document}
              
            
